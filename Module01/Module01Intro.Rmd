---
subtitle: "TMA4315 Generalized linear models H2024"
title: "Module 1: INTRODUCTION"
author: "Mette Langaas, Bob O'Hara, Department of Mathematical Sciences, NTNU"
output: #3rd letter intentation hierarchy
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
  # pdf_document:
  #   toc: true
  #   toc_depth: 2
 # beamer_presentation:
 #   keep_tex: yes
 #   fig_caption: false
 #   latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 

# Introduction

[Classnotes 23.08.2018](https://www.math.ntnu.no/emner/TMA4315/2018h/TMA4315M1H2018.pdf)

## Aim of this module

* this course: expanding the linear regression framework
* short presentation of all course modules
* learning outcome
* student learning styles
* interactive lectures: what, why and how?
* practical details of the course (Blackboard)

* core concept: the exponential family of distributions
* learn about - and use - `R`, `Rstudio`, `R Markdown`, and get familiar with related topics 
* get up to speed on R (and writing reports in R markdown) to be able to do the 3*10-points compulsory exercises by doing recommended exercises

---

## Expanding the linear regression framework 

You know multiple linear regression (from TMA4267 Linear statistical models or TMA4255 Applied Statistics or TMA4268 Statistical learning). We will stay with regression (for the whole course) - but make expansions in several directions.

What will not change: 

* our target is _a random response $Y_i$_ (from some statistical distribution): continuous, binary, nominal or ordinal, we have 

* _fixed covariates (or explanatory variables) $X_i$_ (in a design matrix): quantitative or qualitative, and 

* _unknown regression parameters $\beta$_.

We will consider relationships between the _conditional mean of $Y_i$_, $\text{E}(Y_i\mid {\bf x}_i)=\mu_i$, and linear combinations of the covariates in _a linear predictor_ $\eta_i=\beta_0+\beta_1 x_{i1}+\cdots +\beta_k x_{ik}={\bf x}_i^T {\bf \beta}$.

For most of the course we will assume observation pairs ($Y_i,{\bf x}_i$) are independent $i=1,\ldots,n$, but we will also consider clustered pairs (in Module 7+8: Linear mixed effects models LMM and Generalized linear mixed effects models GLMM).

---

# Course content and modules

Univariate exponential family. Multiple linear regression. Logistic regression. Poisson regression. General formulation for generalised linear models with canonical link. Likelihood-based inference with score function and expected Fisher information. Deviance. AIC. Wald and likelihood-ratio test. Linear mixed effects models with random components of general structure. Random intercept and random slope. Generalised linear mixed effects models. 
Strong emphasis on programming in R. 

Possible extensions: quasi-likelihood, over-dispersion, models for multinomial data, analysis of contingency tables, quantile regression. 

H2018 extensions: categorical regression (models for multinomial data) and contingency tables, score tests.

**Textbook:** Fahrmeir, Kneib, Lang, Marx (2013): "Regression. Models, Methods and Applications" <https://link.springer.com/book/10.1007%2F978-3-642-34333-9> (free ebook for NTNU students).
Tentative reading list: main parts of Chapters 2, 3 (repetition), 5, 6, 7, Appendix B.4.

---

## The modules - in short

The modules of this course are:

1. Introduction (the module page you are reading now) [week 34]

2. Multiple linear regression (emphasis on likelihood) [week 35-36]

3. Binary regression (binary individual and grouped response) [week 37-38]

4. Poisson and gamma regression (count, non-normal continuous) [week 39-40]

5. GLM in general and quasi likelihood (exponential family, link function) [week 41]

6. Categorical regression and contingency tables [week 43]

7. Linear mixed models (clustered data, repeated measurements) [week 44-45]

8. Generalized mixed effects models [week 46]

9. Discussion and conclusion [week 47]

---

## Module 2: Multiple linear regression

A lot of the methods used for GLMs come from linear regression, so we start from there. This module reviews that material, but re-frames the concepts slightly, so the leap to GLMs is easier.

### Example: Exam TMA4267, V2017, Problem 2: CVD

The Framingham Heart Study is a study of the etiology (i.e. underlying causes) of cardiovascular disease (CVD), with participants from the community of Framingham in Massachusetts, USA <https://www.framinghamheartstudy.org/>. This dataset is subset of a teaching version of the Framingham data, used with permission from the Framingham Heart Study.

---

We will focus on modelling systolic blood pressure using data from $n=2600$ persons. For each person in the data set we have measurements of the following seven variables

* `SYSBP` systolic blood pressure (mmHg),

* `SEX` 1=male, 2=female,

* `AGE` age (years) at examination, 

* `CURSMOKE` current cigarette smoking at examination: 0=not current smoker, 1= current smoker,

* `BMI` body mass index (kg/m$^2$),

* `TOTCHOL` serum total cholesterol (mg/dl), and

* `BPMEDS` use of anti-hypertensive medication at examination: 0=not currently using, 1=currently using.

A multiple normal linear regression model was fitted to the data set with $-\frac{1}{\sqrt{SYSBP}}$ as response and all the other variables as covariates. 

---

```{r CVDread, eval=TRUE,include=FALSE,message=FALSE}
#this data set is not publicly available
thisds=dget("https://www.math.ntnu.no/emner/TMA4315/2017h/data/BPtma4267P2.dd")
dim(thisds)
colnames(thisds)
```

The data set is here called `thisds`.

\tiny
```{r CVDanalyse, eval=TRUE,include=TRUE,message=FALSE}
modelB=lm(-1/sqrt(SYSBP)~SEX+AGE+CURSMOKE+BMI+TOTCHOL+BPMEDS,data=thisds)
summary(modelB)
```
<!-- 
residB=rstudent(modelB)
plot(modelB$fitted.values,residB,pch=20)
qqnorm(residB,pch=20)
qqline(residB)
library(nortest)
ad.test(residB)
-->
\normalsize

---

**PLAN:** You recapitulate what you have learned in TMA4267 Linear statistical models, and in the plenary lectures we focus on a three-step model, likelihood theory and formal inference connected to the likelihood. Instead of sums-of-squares of error (MSE, RSS) we will use deviance. 

In Compulsory exercise 1 you make your own `mylm` function to perform MLR.

**Textbook**: Chapter 3 (from TMA4267) and parts of Appendix B4.

---

## Module 3: Binary regression

How can be model a response that is not a continuous variable? This is where GLMs start to become useful. Here we look at present/absent, true/false, healthy/diseased, and how to model this.

### Example: Mortality of beetles

About 60 beetles were exposed to each of 8 different concentrations of CS$_2$ (data on log10-dose), and the number killed at each of the concentrations were recorded.

```{r beetles, eval=TRUE,include=TRUE,message=FALSE}
library(investr)
head(beetle)
frac=beetle$y/beetle$n
plot(beetle$ldose,frac,pch=20)
```

---

What might be the distribution of the number of dead beetles, $Y_i$ at a given dose $x_i$? Dose $x_i$ was given to $n_i$ beetles.

---

\[ Y_i=bin(n_i,\pi_i)\]
where $\pi_i$ =probability for a beetle to die at dose $x_i$ and $n_i$= number of beetles treated with dose $x_i$. A linear model for $\pi_i$ estimated by ordinary least squares is problematic because

* $0 \le \pi_i \le 1$ can not be guaranteed by a linear expression $\beta_0+\beta_1 x_i$, and 

* $\text{Var}(Y_i) =n_i \pi_i (1-\pi_i)$ is non-constant (heteroscedastic) variance.

---

The "usual" solution^[the usual solution is not the solution that was originally used on this data, or the one that is "best". We will cover those too, though] to this is _logistic regression_ where the relationship between the mean of the response and the predictor is not linear, but instead
\[ \ln(\frac{\pi_i}{1-\pi_i})= \beta_0+\beta_1 x_i \]
or equivalently
\[\pi_i=\frac{\exp(\beta_0+\beta_1 x_i)}{1+\exp(\beta_0+\beta_1 x_i)}\]

Then $0\le \pi_i\le 1$. We estimate the model by Maximum Likelihood (ML), while taking into account that the responses are binomially distributed. 

---

\tiny

```{r beetlesglm, eval=TRUE,include=TRUE,message=FALSE}
fit=glm(cbind(beetle$y,beetle$n-beetle$y)~ldose,data=beetle,family=binomial)
summary(fit)
```

\normalsize

---

\tiny

```{r}
thisrange=range(beetle$ldose)
xs=seq(thisrange[1],thisrange[2],length=100)
predicted=predict(fit,newdata=data.frame(ldose=xs),type="response")
plot(beetle$ldose,frac)
lines(xs,predicted)
```

\normalsize

---

**PLAN:** In this module we will study the binary regression, work on parameter estimation and interpretation of parameter estimates using odds, work with both individual and grouped data, test linear hypotheses, look at criteria for model fit and model choice, and discuss overdispersion.

**Textbook:** 2.3 and 5.1.

---

## Module 4: Poisson and gamma regression

Count data - the number of times and event occurs - is common. In one famous study British doctors were in 1951 sent a questionnaire about whether they smoked tobacco - and later information about their death were collected. Questions that were asked were: Is the death rate higher for smokers than for non-smokers? If so, by how much? And, how is this related to age?

\tiny

```{r}
library(boot) #n=person-year, ns=smoker-years, age=midpoint 10 year age group, 
#y=number of deaths due to cad, smoke=smoking status
head(breslow,n=10)
```

\normalsize

---

To investigate this we will look at different ways of relating the expected number of deaths and the number of doctors at risk in the observation period for each smoke and age group. We will do this by assuming a Poission distribution for the number of deaths, and linking this to a linear predictor. 

When we work with continuous data - like life times, costs and claim sized - these may not be negative, and the their distribution often follow a right skewed distribution. We will look at effect a one of more covariates that may work multiplicative on the response and see how we may fit that using gamma regression on the log scale of the response.

**Textbook:** 5.2 and 5.3

---

## Module 5: GLM in general (and quasi likelihood — if time)

We will see that normal, binary, Poisson and gamma regression all have the same underlying features:

1. The mean of the response, $\mu_i=\text{E}(Y_i)$, is connected to the linear predictor $\eta_i={\bf x}_i^T \beta$ by a link function: $\eta_i=g(\mu_i)$ or, alternatively, by a response function $\mu_i=h(\eta_i)$ - where $g=h^{-1}$ (inverse functions).

2. The distribution of the response can be written as a univariate exponential family (we work with that in this first module).

This leads to a unified framework, and maximum likelihood estimation can be written on a generalized form for all the GLMs. In addition we can present statistical inference and asymptotic properties of estimators on a common form. Finally, we may expand this to quasi-likelihood models by just specifying mean and variance (not distribution) and solve using generalized estimation equations.

---

This part is rather mathematical - but is built on the findings of modules 1-4.

**Textbook:** 5.4 and 5.5 


---

## Module 6: Categorical regression and contingency tables

Here our response variable has more than two categories, and these categories can either be unordered or ordered.
Examples of categorical responses include (unordered) data in infection (no, or so-called type I or type II) after Caesarian delivery, or (ordered) data on degree of defoliation of trees (nine ordered categories).

We will use the multinomial distribution as the distribution for the response, and work mainly with grouped data - that often can be presented in a contingency table.

\tiny

```{r}
ds=read.table("https://www.math.ntnu.no/emner/TMA4315/2017h/data/caesarian.raw",header=TRUE)
head(ds)
```

\normalsize

---

For unordered categories (like the Caesarian delivery data) we will use many logistic regressions - each between one category and a chosen reference category.
For ordered categories (like the defoliation of trees) we will use a cumulative model, also called a proportional odds model.

---

If time permits we will also look briefly at exact and asymptotic inference (Fishers exact test and Pearsons Chisquare test) for contingency tables (unordered categories), which is closely related to the GLM-presentation.

**Textbook:** Chapter 6, and possibly extra materiale on the Fisher and Chi-square test (if time permits).

Compulsory exercise 2 will cover modules 3-6.

---

## Module 7: Linear mixed effects models

This module moves on from GLMs towards GLMMs^[there are also GLLVMs, which we will avoid]. So far we have assumed that parameters are fixed. Here we move to models where some parameters are themselves seen are drawn from a distribution; they are called **random effects**.

In a study on the effect of sleep deprivation the average reaction time per day were measured. On day 0 the subjects had their normal amount of sleep. Starting that night they were restricted to 3 hours of sleep per night. The observations represent the average reaction time on a series of tests given each day to each subject. This was measured for 18 subjects for 10 days (days 0-9). 

---

\tiny

```{r,error=FALSE,message=FALSE, warning=FALSE}
library(lme4)
library(ggplot2) # see more on ggplot later in this module
gg <- ggplot(sleepstudy, aes(x = Days, y = Reaction))
gg <- gg + geom_point(color = "blue", alpha = 0.7)
gg <- gg + geom_smooth(method = "lm", color = "black")
gg <- gg + theme_bw()
gg <- gg + facet_wrap(~Subject)
gg
```

\normalsize

---

We observe that each subject’s reaction time increases approximately linearly with the number of sleepdeprived
days. But, it appears that subjects have different slopes and intercepts. 

As a first model we may assume that there is a common intercept and slope for the population - called fixed effects, but allow for random deviations for the intercept and slope for each individual. In linear mixed effects models we assume that the random intercepts and slopes are drawn from normal distributions and estimate the variance in these distribution. Such a model will make observations correlated within subjects. 

---

\tiny


```{r}
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
summary(fm1)
```

\normalsize

Here the population fixed effects estimates are an intercept of 251.4 ms and a slope of 10.47 ms/day. The random effects for the intercept and the slope have estimated standard deviations 24.74 ms and 5.92 ms/day. 

----

In this module we will look at different models for clustered (schools, families) and repeated measurement (e.g. over time) using regression with fixed and random effects. 


**Textbook:** 2.4, 7.1, 7.3

---

## Module 8: Generalized linear mixed effects models

We generalize our model in Module 7 - on normal responses - to binary (and possibly Poisson) responses.

**Textbook:** 7.2, 7.5, 7.7

Compulsory exercise 3 will cover modules 7-8.

## Module 9: Discussion and conclusions

---

## Common themes for all modules

1. Model specification: an equation linking the response and the explanatory variables, and a probability distribution for the response.

2. Estimation of the parameters in the model

3. Checking the adequacy of the model, how well it fits the data.

4. Inference: confidence intervals, hypothesis tests, interpretation of results, prediction of future responses.

Both theoretic derivations and practical analysis in R will be emphasized.

---

# Learning outcome

**Knowledge**.

The student can assess whether a generalised linear model can be used in a given situation and can further carry out and evaluate such a statistical analysis. The student has substantial knowledge of generalised linear models and associated inference and evaluation methods. This includes regression models for Gaussian distributed data, logistic regression for binary and multinomial data, Poisson regression and log-linear models for contingency tables. 

The student has theoretical knowledge about linear mixed models and generelized linear mixed effects models, and associated inference and evaluation of the models. Main emphasis is on Gaussian and binomial data.


**Skills**.

The student can assess whether a generalised linear model or a generalized linear mixed model can be used in a given situation, and can further carry out and evaluate such a statistical analysis. 


---

# Learning styles

We (probably) all have different ways in which we learn - and we have different learning ambitions when attending a course.

Back in 1988 Felder and Silverman published an article where they suggested that there was a mismatch between the way students learn and the way university courses were taught (in Science, Technology, Engineering and Mathematics=STEM). They devised a taxonomy for learning styles - where four different axis are defined:

---

1) **active - reflective**: How do you process information: actively (through physical activities and discussions), or reflexively (through introspection)?

2) **sensing-intuitive**: What kind of information do you tend to receive: sensitive (external agents like places, sounds, physical sensation) or intuitive (internal agents like possibilities, ideas, through hunches)?

3) **visual-verbal**: Through which sensorial channels do you tend to receive information more effectively: visual (images, diagrams, graphics), or verbal (spoken words, sound)?

4) **sequential - global**: How do you make progress: sequentially (with continuous steps), or globally (through leaps and an integral approach)?

Here are a few words on the [four axis](http://www4.ncsu.edu/unity/lockers/users/f/felder/public//ILSdir/styles.pdf)

---

The idea in the 1988 article was that by _acknowledging these different learning style axes it was possible to guide the teachers to choose teaching styles that matched the learning styles of the students_. That is, many students (according to Felder and coauthors) have a visual way of learning, and then teachers should spend time devising visual aids (in addition to verbal aids - that were the prominent aids in 1988), and so on. 

**However, studies show that the students should use _many_ different learning resources - not only one favourite (not only go to plenary lectures or not only read in the book).**

---

In this GLM course I have designed different learning resources, and hope that many of these match your way of learning. To help me (and maybe for you to get some insight into your own learning style) 

**I ask you to answer a standardized set of questions made by Felder et al (44 questions with two possible answers), and then report your results to me in a Google form**. 

---

You can report your scores anonymously, or by giving our name. If you do this anonymously I will have information on the class level, and if you do this with your name I get to know a bit about how you learn and I can use the results to help to construct student groups for the interactive lectures. Your results will only be used by me, and I will not show them to other people (students or staff). This means that this is not used for research, but to increase the quality of the GLM course (in total and for each one of you). I will never discuss your personal results in class, but are very eager to discuss results on the class level - and use these when designing new learning resources.

Here is the [questionarie](https://www.webtools.ncsu.edu/learningstyles/) (maybe do a screen shot of your results -the results only appear on a web page and is not saved or emailed to you or anyone).

I have taken the test and these were my results:
I scored 3 on the active side of the active-reflective scale, 1 on the sensing side of the sensing-intuitive scale, 5 on the visual side on the visual-verbal scale and finally 5 on the global side of the sequential-global scale. In the Google form I would then report to have a "active value" for the active-reflective axis, and then report the value to be 3. Then I would choose "sensing value" on the sensoring-intuitive axis and report the value to be 1,  I will choose "visual value" and report 5, and finally choose "global value" and report 5. (Values below 5 are reported to be weak, and this means that there is no strong preference on that axis.)

Here is the [Google form where I ask that you write your 4 scores](https://goo.gl/forms/p77EFhQabe9BIZT32)

After you have submitted your scores please go back and read the description of the four axis, but this time [focus on the advice for the different type of learners](http://www4.ncsu.edu/unity/lockers/users/f/felder/public//ILSdir/styles.pdf)

If you are curios about the work of Felder and coauthors, more resources can be found here: <http://educationdesignsinc.com/>

# Learning resources in the GLM course

##The module pages

I have divided the GLM course into modular units with specific focus, in order to use smaller units (time and topic) to facilitate learning.

* The topic of each module on the agenda for 1—2 weeks of study.
* All activity points to module pages.
* Mathematics in LaTeX (also derivations present), figures and examples with R, all R code visible. 

---

### Structure of module pages

1) Introduction and aim
2) Motivating example
3) Theory—example loop
4) Recommended exercises
5) References, packages to install.

---

### How to use the module pages?

* A slides version (output: beamer_presentation) of the pages used in the plenary lectures.
* A webpage version (output: html_document) used in the (so-called) interactive lectures.
* A document version (output: pdf_document) used for student self study.
* The Rmd version — used as notebook to investigate changes to the R code.
* Additional class notes (written in class) linked in.

The module pages are the backbone of the course!

---

**Active students — deep learning?** Since active students are more able to analyse, evaluate and synthesise ideas?

* Provide learning environments, opportunities, interactions, tasks and instruction that foster deep learning.
* Provide guidance and support that challenges students based on their current ability. 
* Students discover their current strengths and weaknesses and what they need to do to improve. 

What are student active learing methods/tasks?

* Pause in plenary lecture to ask questions and let students think and/or discuss.
* In-class quizzes (with the NTNU invention Kahoot!) — individual and team mode.
* Projects — individual or in groups.
* Group discussion.

Now:  plenary and _interactive lectures_.

---

## The plenary lectures (PL)

* for each module we start with a plenary lecture to introduce the aims,
* use real data to examplify what to learn, why this is useful and what this is used in society
* then we move to notation and focus on the model used
* theory is then presented (writing - not slides), discussed and
* mixed with use of R and data analysis.

The plenary lectures is rather passive in nature - for the students - and held in classical auditorium. They provide the first step into the new module.

**Q:** What are advantages of attending a plenary lecture (as compared to reading the text book or the module pages, or watching videoes)? Do you plan to attend the plenary lectures?

---

## The interactive lectures (IL)

has focus on student activity and understanding though discussing with fellow students and with the lecturer/TA - in groups.

### Smia (the smithy)
<!---
![](../../ACT/Smia_collage.jpg){width=250px}
--->

A room where interaction and activity is in focus. Flat floor with group tables, whiteboard and screen — PC and electricity outlets. 50 students.

\tiny \url{https://www.ntnu.no/laeringsarealer/smia}\normalsize

---


1. Students arrive and are divided into groups (different criteria will be used). Short presentation round (name, study programme, interests) in the groups. One student (the "manager") log in to the PC at each table, or connect her/his own laptop and display the module page.

2. Lecturer gives a _short_ introduction to current state, and present a problem set (mainly exam problem).

---

3. Students work together in the group on the problem set. The problems are presented on the digital screen, and the students discuss by interacting around the screen and often by running (ready-made) R code and interpreting analysis output - all presented on the digital screen. 

4. If the problem is of a theoretical flavour, or drawing is needed - the students work on the whiteboards next to the digital screen. One student may act as "secretary".

---

5. Lecturer summarizes solutions to the problem with input from the student groups.

6. This summarizing the first 45 minutes, then there is a break (with light refreshments) and then repeat 1-5 in the second hour.

**More pictures of how the students in H2017 worked will be shown in the PL.**

---


## Statements from focus groups H2017

(two groups of 4 students each, one hour "interviews" by external evaluator - anonymous contributtions)

###The concept

**Student A:** We are taught in a different way than what we have experienced earlier — sitting in groups, working on problem sets and discussing. No, never experienced this before — and we are master students. Where was all this earlier?

**Student B:** It is very nice to have two hours every week to discuss with the others, and be able to explain to each other and work with the course material from a new point of view. We are not told what is right, but we spend time finding that out — together.

They also commented that the reading list was short and that they did not think they had to prepare much for the exam — they felt that they really understood and were up to date. 

---

###Learning outcome in group setting and new concepts

**Student C:** For most sessions I feel I learnt a lot. I remember the concept we work on has been talked about in the plenary lectures, and then I talk about the details with the others in the group and get to explain to the others — then I feel that I really know this concept. I do not really learn so much new stuff, but I learn what we have already gone through in the plenary lectures a lot better.

**Student D:** And, we get a confirmation that we have understood what we were taught in the plenary lecture. Yes, I know this concept - and so on - and I have not misunderstood - which may often happen. If I have misunderstood I get corrected here in the interactive lecture - this makes the learning more targeted (not so abstract).

**Student E:** Yes, I agree, what we learn becomes reinforced. Personally I find it hard to learn new concepts in a group setting.

Comment: hard to come to IL if not up-to-date on reading list (e.g. not read by yourself or attended PL).

---

### But, they were also worried: 

**Student F:** I believe Mette cannot go so deep in the plenary lecture - compared to when we had the double amount of plenary lectures. She plans for us to learn by ourselves, which I think is a good thing. I beleive that we have a greater gain from learning together, and from seeing each others problems, and we learn from each other.

**Student G:** I agree, I think it is more challenging for a lecturer to divide the course in interactive and plenary lectures than only using plenary lectures. The lecturer needs to teach in two different ways, but also to try to cover all material in effectively shorter time. Maybe this results in us loosing the depth understanding, maybe that is how it is, and that is sad.

This was the main motivation behind the module pages — having the full story written out, but choosing parts to present in the plenary lectures and parts in the interactive lectures. 

---

**Questions:**

* Who are the interactive lectures for? 
* What are advantages of attending an interactive lecture? 
* When you finish your studies and head for a job - go you think the skills developed in the interactive lectures will be in demand? 
* Do you think the interactive lectures will be challenging for you to attend? Why? 
* How can the lecturer help you make this easier? Personal adjustment can be made.
* If the IL worked well in 2017, does it mean that it will also work in 2018?

---

## The compulsory exercises

has mainly focus on programming and interpretation - with some theory - and can be worked on in small groups (1-3). Will be a test of acquired understanding, and will constitute 30% of the final evaluation. 

---

# Practical details 

go to Blackboard
[student log-in](https://innsida.ntnu.no/bb-student) or 
[guest access](https://ntnu.blackboard.com/webapps/login?action=guest_login&new_loc=/webapps/blackboard/execute/courseMain?course_id=_11002_1).

---

# Core concept: Exponential family of distributions 

In this course we will look at models where the distribution of the response variable, $y_i$, can be written in the form of a _univariate exponential family_
\[ f(y_i\mid \theta_i)=\exp \left( \frac{y_i \theta_i-b(\theta_i)}{\phi}\cdot w_i + c(y_i, \phi, w_i) \right) \]
where

* $\theta_i$ is called the canonical parameter and is a parameter of interest

* $\phi$ is called a nuisance parameter (and is not of interest to us=therefore a nuisance (plage))

* $w_i$ is a weight function, in most cases $w_i=1$

* b and c are known functions.

It can be shown that $\text{E}(Y_i)=b'(\theta_i)$ and $\text{Var}(Y_i)=b''(\theta_i)\cdot \frac{\phi}{w}$.

Remark: slightly different versions of writing the exponential family exists, but we will use this version in our course (a different version might be used in TMA4295, but the basic findings are the same).

----

